{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80190dba",
   "metadata": {},
   "source": [
    "# Drowsiness Detection Notebook\n",
    "This Jupyter notebook replicates the GUI functionality described earlier. It allows you to:\n",
    "\n",
    "* Detect multiple people in images or video streams using **YOLOv8**.\n",
    "* Determine whether each detected face is **awake (green box)** or **sleeping (red box)** via eye–aspect ratio (EAR).\n",
    "* Display how many people are sleeping along with (placeholder) age estimates.\n",
    "\n",
    "The notebook is CPU-friendly but will use a GPU automatically if one is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ff3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2, dlib, numpy as np, math, random, os, urllib.request\n",
    "from imutils import face_utils\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8922f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading YOLOv8n weights…\n",
      "Downloading Dlib facial landmark model (99 MB)…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download YOLOv8n weights if not present\n",
    "if not os.path.exists('yolov8n.pt'):\n",
    "    print('Downloading YOLOv8n weights…')\n",
    "    urllib.request.urlretrieve('https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt', 'yolov8n.pt')\n",
    "\n",
    "# Download dlib face-landmark model if not present\n",
    "if not os.path.exists('shape_predictor_68_face_landmarks.dat'):\n",
    "    print('Downloading Dlib facial landmark model (99 MB)…')\n",
    "    urllib.request.urlretrieve(\n",
    "        'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2',\n",
    "        'shape_predictor_68_face_landmarks.dat.bz2')\n",
    "    import bz2, shutil\n",
    "    with bz2.open('shape_predictor_68_face_landmarks.dat.bz2', 'rb') as f_in, open('shape_predictor_68_face_landmarks.dat', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "    os.remove('shape_predictor_68_face_landmarks.dat.bz2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa9ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load YOLOv8 for person detection\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Initialize dlib face detector & predictor\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbb0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, math, random\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = math.dist(eye[1], eye[5])\n",
    "    B = math.dist(eye[2], eye[4])\n",
    "    C = math.dist(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def detect_drowsiness(frame, ear_threshold=0.25):\n",
    "    \"\"\"Detect persons and classify each as sleeping/awake with placeholder age.\"\"\"\n",
    "    results = model.predict(source=frame, classes=[0], conf=0.25, verbose=False)[0]\n",
    "    detections = []\n",
    "    for box in results.boxes.xyxy.cpu().numpy():\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "        person_crop = frame[y1:y2, x1:x2]\n",
    "        gray = cv2.cvtColor(person_crop, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detector(gray, 0)\n",
    "        status = 'Awake'\n",
    "        age = None\n",
    "        for face in faces:\n",
    "            shape = landmark_predictor(gray, face)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS['left_eye']\n",
    "            (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS['right_eye']\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            ear = (eye_aspect_ratio(leftEye) + eye_aspect_ratio(rightEye)) / 2.0\n",
    "            status = 'Sleeping' if ear < ear_threshold else 'Awake'\n",
    "            age = random.randint(18, 60)  # placeholder\n",
    "            break\n",
    "        detections.append({'bbox': (x1, y1, x2, y2), 'status': status, 'age': age})\n",
    "    return detections\n",
    "\n",
    "def annotate_frame(frame, detections):\n",
    "    sleeping_count = 0\n",
    "    ages = []\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det['bbox']\n",
    "        color = (0, 0, 255) if det['status'] == 'Sleeping' else (0, 255, 0)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        label = f\"{det['status']}\" + (f\", {det['age']}y\" if det['age'] else '')\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        if det['status'] == 'Sleeping':\n",
    "            sleeping_count += 1\n",
    "            if det['age']:\n",
    "                ages.append(det['age'])\n",
    "    return frame, sleeping_count, ages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e696424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload an image:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7149dbb500334000af1dc646d0ac04fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#@title Upload and test on an image { run: \"auto\" }\n",
    "from IPython.display import clear_output, Image as IPImage\n",
    "uploader = widgets.FileUpload(accept='image/*', multiple=False)\n",
    "print('Upload an image:')\n",
    "\n",
    "display(uploader)\n",
    "\n",
    "def on_upload_change(change):\n",
    "    if uploader.value:\n",
    "        content = next(iter(uploader.value.values()))['content']\n",
    "        img_array = np.frombuffer(content, dtype=np.uint8)\n",
    "        frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        detections = detect_drowsiness(frame)\n",
    "        annotated, sleeping, ages = annotate_frame(frame.copy(), detections)\n",
    "        annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "        clear_output(wait=True)\n",
    "        print(f'Sleeping people: {sleeping}', end='')\n",
    "        if ages:\n",
    "            print(' - ages:', ', '.join(map(str, ages)))\n",
    "        else:\n",
    "            print()\n",
    "        display(IPImage(data=cv2.imencode('.png', annotated)[1].tobytes()))\n",
    "\n",
    "a = uploader.observe(on_upload_change, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56846387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide a valid video file path in video_path variable above.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Demo processing a short video file (change path as needed)\n",
    "video_path = 'sample_video.mp4'  # replace with your file or leave blank for webcam\n",
    "if not os.path.exists(video_path):\n",
    "    print('Provide a valid video file path in video_path variable above.')\n",
    "else:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    out_widget = widgets.Image()\n",
    "    display(out_widget)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        detections = detect_drowsiness(frame)\n",
    "        annotated, sleeping, ages = annotate_frame(frame.copy(), detections)\n",
    "        annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "        _, png = cv2.imencode('.png', annotated)\n",
    "        out_widget.value = png.tobytes()\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60947e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
